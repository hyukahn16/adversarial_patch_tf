{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC6ES17KUbKcyuXn1qlkdB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of Adversarial Patch\n",
        "\n",
        "https://arxiv.org/pdf/1712.09665.pdf\n",
        "\n",
        "https://github.com/jhayes14/adversarial-patch\n",
        "\n",
        "https://github.com/A-LinCui/Adversarial_Patch_Attack\n",
        "\n",
        "Original paper tested with inceptionv3, restnet50, xception, VGG16, and VGG19\n",
        "\n",
        "2 whitebox attacks, 1 blackbox attack, and a control patch of a toaster"
      ],
      "metadata": {
        "id": "VCeKqNY0iChT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "print(\"Tensorflow version: \" + str(tf.__version__))\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhuVOj0rbV5P",
        "outputId": "8239a805-47a0-4258-8299-61b192d79c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device not found\n",
            "Tensorflow version: 2.11.0\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "data_dir = \"/content/drive/My Drive/imagenet/val\"\n",
        "!ls \"/content/drive/My Drive/imagenet\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcMyfGIey9lK",
        "outputId": "81494aba-2780-4ad3-8e81-749d586684d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "adversarial.jpeg    patch_100.png  patch_180.png  patch_80.png\n",
            "final_patch_0.jpeg  patch_120.png  patch_200.png  patches\n",
            "final_patch.jpeg    patch_140.png  patch_40.png   tests\n",
            "patch_0.png\t    patch_160.png  patch_60.png   val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMETERS\n",
        "BATCH_SIZE = 1\n",
        "TARGET_SIZE = (299, 299)\n",
        "IMAGE_HEIGHT = TARGET_SIZE[0]\n",
        "IMAGE_WIDTH = TARGET_SIZE[1]\n",
        "PATCH_PROP = 0.05 # proportion of patch w.r.t image\n",
        "\n",
        "ATTACK_CLASS = 859 # 859 == toaster\n",
        "TARGET_CONF_SCORE = 0.9\n",
        "MAX_ITER = 200\n",
        "LR = 1\n",
        "\n",
        "CHAN_FIRST = [0, 3, 1, 2]\n",
        "CHAN_LAST = [0, 2, 3, 1]"
      ],
      "metadata": {
        "id": "bwZ2gFBDOroE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    validation_split=0.5)\n",
        "\n",
        "print(\"Training data\")\n",
        "train_gen = img_gen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='training')\n",
        "\n",
        "print(\"Validation data\")\n",
        "val_gen = img_gen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation')\n",
        "\n",
        "print(\"Batch size       = {}\".format(BATCH_SIZE))\n",
        "print(\"Image dimensions = {} x {}\".format(TARGET_SIZE[0], TARGET_SIZE[1]))"
      ],
      "metadata": {
        "id": "lRoizj2ny471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956cc97f-60cd-42df-c3fc-464b073f1c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data\n",
            "Found 25064 images belonging to 1000 classes.\n",
            "Validation data\n",
            "Found 25053 images belonging to 1000 classes.\n",
            "Batch size       = 1\n",
            "Image dimensions = 299 x 299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model to attack\n",
        "inceptionv3 = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000, # Imagenet has 1000 classes\n",
        "    classifier_activation=None)\n",
        "\n",
        "inceptionv3.trainable = False"
      ],
      "metadata": {
        "id": "fiLh19ugiGYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5f0a11-764b-4995-bc99-14a78da959ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96112376/96112376 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_patch():\n",
        "    # Initialize adversarial patch w/ random values\n",
        "    img_size = IMAGE_HEIGHT * IMAGE_WIDTH\n",
        "    patch_size = img_size * PATCH_PROP\n",
        "    patch_dim = int(patch_size**(0.5))\n",
        "    patch = np.random.rand(1, 3, patch_dim, patch_dim)\n",
        "    print(\"Patch shape = \" + str(patch.shape))\n",
        "    return patch\n",
        "\n",
        "patch = initialize_patch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF75Gqsjgm0r",
        "outputId": "5920b763-f186-4b36-aa18-b97ad8812205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patch shape = (1, 3, 66, 66)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prob_and_class(pred_logits):\n",
        "    probs = tf.nn.softmax(pred_logits, axis=1)\n",
        "    pred_class = tf.argmax(probs, axis=1)\n",
        "    prob = probs[:, pred_class[0]]\n",
        "    return prob[0], pred_class[0], probs"
      ],
      "metadata": {
        "id": "nOwskAg3azIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/39465526/tensorflow-optimize-over-input-with-gradient-descent\n",
        "# https://www.tensorflow.org/guide/autodiff\n",
        "# https://stackoverflow.com/questions/37689423/convert-between-nhwc-and-nchw-in-tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def attack(model, pred_logits, data, patch_dummy, mask):\n",
        "    data = tf.transpose(data, CHAN_FIRST)\n",
        "    cutout_data = tf.multiply((1-mask), data)\n",
        "    adv_img = cutout_data + patch_dummy\n",
        "    adv_img = tf.transpose(adv_img, CHAN_LAST)\n",
        "    \n",
        "    # pred_probs.shape == (batch size, # classes)\n",
        "    pred_probs = tf.nn.softmax(pred_logits)\n",
        "    attack_conf = pred_probs[:,ATTACK_CLASS][0]\n",
        "\n",
        "    iter = 0\n",
        "    while attack_conf < TARGET_CONF_SCORE and iter < MAX_ITER:\n",
        "        with tf.GradientTape() as tape:\n",
        "            # print(\"Optimizing input iteration: {} | attack conf: {}\".format(iter, attack_conf))\n",
        "\n",
        "            adv_img = tf.Variable(adv_img, trainable=True, name=\"adversarial_patch_toaster\", dtype=tf.float32)\n",
        "            adv_pred_logit = model(adv_img) # Output is softmax-ed\n",
        "            adv_pred_log_prob = tf.nn.log_softmax(adv_pred_logit, axis=1)\n",
        "\n",
        "            attack_log_prob = tf.gather(adv_pred_log_prob, [ATTACK_CLASS], axis=1)[0][0]\n",
        "\n",
        "            # Optimize patch\n",
        "            grad = tape.gradient(attack_log_prob, adv_img)\n",
        "            grad = tf.transpose(grad, CHAN_FIRST)\n",
        "            patch_grad = tf.multiply(mask, grad)\n",
        "            patch_grad = tf.transpose(patch_grad, CHAN_LAST)\n",
        "            adv_img = adv_img + (LR * patch_grad)\n",
        "            adv_img = tf.clip_by_value(adv_img, 0.0, 1.0)\n",
        "\n",
        "            if iter % 50 == 0:\n",
        "                print(\"Optimizing input iteration: {} | New attack conf: {}\".format(iter, attack_conf))\n",
        "\n",
        "            iter += 1\n",
        "\n",
        "            # Check attack confidence score\n",
        "            adv_pred_logit = model(adv_img) # Output is softmax-ed\n",
        "            pred_class = tf.math.argmax(adv_pred_logit, axis=1)\n",
        "            adv_pred_prob = tf.nn.softmax(adv_pred_logit, axis=1)\n",
        "            attack_conf = tf.gather(adv_pred_prob, [ATTACK_CLASS], axis=1)[0][0]\n",
        "\n",
        "    return adv_img"
      ],
      "metadata": {
        "id": "6iPQck2llG9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dummy_image_with_patch(patch, data_shape):\n",
        "    # Get dummy image which we will place attack patch on.\n",
        "    dummy = np.zeros((data_shape[0], 3, IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "    \n",
        "    # Get width or height dimension of patch\n",
        "    patch_size = patch.shape[-1] # patch.shape == (1, 3, patch_dim, patch_dim)\n",
        "    \n",
        "    for i in range(dummy.shape[0]): # for each data in batch (for jhayes14, 1)\n",
        "        # Perform random # of 90 deg rotations\n",
        "        num_rots = np.random.choice(4)\n",
        "        for j in range(patch[i].shape[0]): # for each RGB value\n",
        "            patch[i][j] = np.rot90(patch[i][j], num_rots)\n",
        "        \n",
        "        # Choose random location on dummy image for patch\n",
        "        patch_x = np.random.choice(IMAGE_HEIGHT)\n",
        "        while patch_x + patch_size > dummy.shape[-1]:\n",
        "            patch_x = np.random.choice(IMAGE_HEIGHT)\n",
        "        patch_y = np.random.choice(IMAGE_WIDTH)\n",
        "        while patch_y + patch_size > dummy.shape[-2]:\n",
        "            patch_y = np.random.choice(IMAGE_WIDTH)\n",
        "       \n",
        "        # Apply patch to dummy image  \n",
        "        dummy[i][0][patch_x:patch_x+patch_size, patch_y:patch_y+patch_size] = patch[i][0]\n",
        "        dummy[i][1][patch_x:patch_x+patch_size, patch_y:patch_y+patch_size] = patch[i][1]\n",
        "        dummy[i][2][patch_x:patch_x+patch_size, patch_y:patch_y+patch_size] = patch[i][2]\n",
        "    \n",
        "    mask = np.copy(dummy)\n",
        "    mask[mask != 0] = 1.0 # Turn patch values into 1's\n",
        "    \n",
        "    return dummy, mask, (patch_x, patch_y)\n",
        "\n",
        "_, _, _ = get_dummy_image_with_patch(patch, (1, 299, 299, 3))"
      ],
      "metadata": {
        "id": "SBYrXs34UCyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_gen, patch):\n",
        "    success = 0\n",
        "    total = 0\n",
        "    recover_time = 0\n",
        "    for batch_idx, (train_data, train_labels) in enumerate(train_gen):\n",
        "        print(\"\\nBatch index: {}\".format(batch_idx))\n",
        "        pred_logits = model(train_data)\n",
        "        pred_prob, pred_class, _ = get_prob_and_class(pred_logits)\n",
        "        real_class = tf.argmax(train_labels, axis=1)[0]\n",
        "\n",
        "        if batch_idx % 2000 == 0:\n",
        "            print(\"Saving patch\")\n",
        "            plt.imsave(\n",
        "                \"/content/drive/My Drive/imagenet/patches/{}.png\".format(batch_idx),\n",
        "                np.array(tf.transpose(patch, CHAN_LAST))[0])\n",
        "        # Only create adversarial examples on examples that were originally classified correctly\n",
        "        if pred_class != real_class:\n",
        "            print(\"Original image was NOT classified correctly.\")\n",
        "            continue\n",
        "\n",
        "        # Get dummy image and mask, both with patch\n",
        "        patch_dummy, mask, patch_loc = get_dummy_image_with_patch(\n",
        "            patch, train_data.shape)\n",
        "        \n",
        "        trained_adv_img = attack(model, pred_logits, train_data, patch_dummy, mask)\n",
        "        \n",
        "        # Compare performance of the adversarial image vs. original image\n",
        "        pred_logits = model(trained_adv_img)\n",
        "        adv_pred_prob, adv_pred_class, all_probs = get_prob_and_class(pred_logits)\n",
        "        orig_class_prob = all_probs[:, pred_class][0]\n",
        "        print(\"Adversarial image's predicted class: {} vs. Original image's predicted class: {}\".\n",
        "              format(adv_pred_class, pred_class))\n",
        "        print(\"Adversarial image predicted class conf: {} vs. Original image predicated class conf: {}\".\n",
        "              format(adv_pred_prob, pred_prob))\n",
        "        print(\"Conf of original class on adversarial image: {}\".format(orig_class_prob))\n",
        "\n",
        "        # Save image if the adversarial image was successful\n",
        "        # if adv_pred_class == ATTACK_CLASS:\n",
        "        #     tf.keras.utils.save_img(\n",
        "        #         \"/content/drive/My Drive/imagenet/adversarial.jpeg\",\n",
        "        #         np.array(trained_adv_img)[0],\n",
        "        #         data_format=\"channels_last\")\n",
        "        \n",
        "        off_h = patch_loc[0]\n",
        "        off_w = patch_loc[1]\n",
        "        targ_h = patch.shape[-2]\n",
        "        targ_w = patch.shape[-1]\n",
        "\n",
        "        patch = tf.image.crop_to_bounding_box(\n",
        "            trained_adv_img, off_h, off_w, targ_h, targ_w)\n",
        "        patch = np.array(tf.transpose(patch, CHAN_FIRST))\n",
        "\n",
        "    return patch"
      ],
      "metadata": {
        "id": "cWxideDXMXmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(inceptionv3, train_gen, patch)"
      ],
      "metadata": {
        "id": "n08idlIGB7HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff0eb15-caf9-4729-9e60-fc3cdd8cf7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch index: 0\n",
            "Saving patch\n",
            "Optimizing input iteration: 0 | New attack conf: 0.0003253435133956373\n",
            "Adversarial image's predicted class: 859 vs. Original image's predicted class: 92\n",
            "Adversarial image predicted class conf: 0.906343400478363 vs. Original image predicated class conf: 0.4244678020477295\n",
            "Conf of original class on adversarial image: 8.147142216330394e-05\n",
            "\n",
            "Batch index: 1\n",
            "Original image was NOT classified correctly.\n",
            "\n",
            "Batch index: 2\n",
            "Original image was NOT classified correctly.\n",
            "\n",
            "Batch index: 3\n",
            "Optimizing input iteration: 0 | New attack conf: 4.42733580712229e-05\n",
            "Adversarial image's predicted class: 859 vs. Original image's predicted class: 328\n",
            "Adversarial image predicted class conf: 0.979576587677002 vs. Original image predicated class conf: 0.9139937162399292\n",
            "Conf of original class on adversarial image: 0.007566686719655991\n",
            "\n",
            "Batch index: 4\n",
            "Optimizing input iteration: 0 | New attack conf: 4.237159009790048e-05\n",
            "Optimizing input iteration: 50 | New attack conf: 0.17529916763305664\n",
            "Optimizing input iteration: 100 | New attack conf: 0.8385235667228699\n",
            "Adversarial image's predicted class: 859 vs. Original image's predicted class: 376\n",
            "Adversarial image predicted class conf: 0.9001216292381287 vs. Original image predicated class conf: 0.9340665340423584\n",
            "Conf of original class on adversarial image: 0.026799432933330536\n",
            "\n",
            "Batch index: 5\n",
            "Original image was NOT classified correctly.\n",
            "\n",
            "Batch index: 6\n",
            "Optimizing input iteration: 0 | New attack conf: 2.087903158098925e-05\n",
            "Optimizing input iteration: 50 | New attack conf: 0.001768244314007461\n",
            "Optimizing input iteration: 100 | New attack conf: 0.023190917447209358\n",
            "Adversarial image's predicted class: 859 vs. Original image's predicted class: 322\n",
            "Adversarial image predicted class conf: 0.940407931804657 vs. Original image predicated class conf: 0.9586199522018433\n",
            "Conf of original class on adversarial image: 0.012959782034158707\n",
            "\n",
            "Batch index: 7\n",
            "Optimizing input iteration: 0 | New attack conf: 3.1612790163393356e-09\n",
            "Optimizing input iteration: 50 | New attack conf: 0.002993345959112048\n",
            "Optimizing input iteration: 100 | New attack conf: 0.04983481019735336\n",
            "Adversarial image's predicted class: 859 vs. Original image's predicted class: 805\n",
            "Adversarial image predicted class conf: 0.9136350750923157 vs. Original image predicated class conf: 0.9999803304672241\n",
            "Conf of original class on adversarial image: 0.03955947607755661\n",
            "\n",
            "Batch index: 8\n",
            "Optimizing input iteration: 0 | New attack conf: 3.6959234421374276e-05\n",
            "Optimizing input iteration: 50 | New attack conf: 0.004419385921210051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_gen, patch):\n",
        "    success = 0\n",
        "    total = 0\n",
        "    for batch_idx, (test_data, test_labels) in enumerate(test_gen):\n",
        "        print(\"Batch index: {}\".format(batch_idx))\n",
        "\n",
        "        # Get dummy image and mask, both with patch\n",
        "        patch_dummy, mask, patch_loc = get_dummy_image_with_patch(\n",
        "            patch, test_data.shape)\n",
        "        \n",
        "        # Add patch to test image\n",
        "        test_data = tf.transpose(test_data, CHAN_FIRST)\n",
        "        cutout_data = tf.multiply((1-mask), test_data)\n",
        "        adv_img = cutout_data + patch_dummy\n",
        "        adv_img = tf.transpose(adv_img, CHAN_LAST)\n",
        "    \n",
        "        if batch_idx % 2000 == 0:\n",
        "            plt.imsave(\n",
        "                \"/content/drive/My Drive/imagenet/tests/{}.png\".format(batch_idx),\n",
        "                np.array(adv_img)[0])\n",
        "\n",
        "        # Compare performance of the adversarial image vs. original image\n",
        "        pred_logits = model(adv_img)\n",
        "        adv_pred_prob, adv_pred_class, all_probs = get_prob_and_class(pred_logits)\n",
        "        # print(\"Adversarial image's predicted class: {}\".format(adv_pred_class))\n",
        "        # print(\"Adversarial image predicted class conf: {}\".format(adv_pred_prob))\n",
        "\n",
        "        total += 1\n",
        "        if adv_pred_class == ATTACK_CLASS:\n",
        "            sucess += 1\n",
        "\n",
        "    return sucess, total"
      ],
      "metadata": {
        "id": "_Q3M5Ozjhh6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "success, total = test(inceptionv3, val_gen, patch)\n",
        "print(success)\n",
        "print(total)"
      ],
      "metadata": {
        "id": "BQp-YTJaNbhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OJbazfDnno1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}